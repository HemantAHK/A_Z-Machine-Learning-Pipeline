{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "A_Z-Machine-Learning-Pipeline.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "d68WpFoyKNTC",
        "LmDrbB-gMk02",
        "3PL70nWBMX7U"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yUqSD9Sf6Xga",
        "colab_type": "text"
      },
      "source": [
        "# Required External Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1AcvXAW86LmE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " # Auto Machine Learning Library\n",
        "!pip install tpot\n",
        "!pip install mlbox\n",
        "!pip install h2o\n",
        "\n",
        "# Python package for stacking (machine learning technique)\n",
        "!pip install vecstack \n",
        "!pip install mlxtend\n",
        "\n",
        "# Model Interpretation Libraries\n",
        "!pip -q install shap\n",
        "!pip -q install lime\n",
        "!pip -q install eli5\n",
        "!pip -q install yellowbrick"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bM0DL52Q8tcQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Basic Library for Data Manupulation\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random as rnd\n",
        "\n",
        "# Reading Diffrent types of data format\n",
        "import pyreadstat \n",
        "import sqlite3\n",
        "from pandas.io import sql\n",
        "import pyreadr\n",
        "\n",
        "\n",
        "#Common Model Helpers\n",
        "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
        "from sklearn import feature_selection\n",
        "from sklearn import model_selection\n",
        "from sklearn import metrics\n",
        "\n",
        "#Visualization\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.pylab as pylab\n",
        "import seaborn as sns\n",
        "from pandas.plotting import scatter_matrix\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "# Importing Models\n",
        "from sklearn import svm, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC, LinearSVC\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "\n",
        "# Importing other tools\n",
        "from sklearn import model_selection\n",
        "from sklearn.metrics import confusion_matrix, classification_report, make_scorer\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_recall_curve\n",
        "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "from sklearn.externals import joblib\n",
        "\n",
        "\n",
        "# Ignoring Warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# External imports\n",
        "from vecstack import stacking\n",
        "from tpot import TPOTClassifier\n",
        "\n",
        "from mlbox.preprocessing import *\n",
        "from mlbox.optimisation import *\n",
        "from mlbox.prediction import *\n",
        "\n",
        "import h20\n",
        "from h2o.automl import H2OAutoML\n",
        "\n",
        "import eli5\n",
        "from eli5.sklearn import PermutationImportance\n",
        "\n",
        "import shap\n",
        "\n",
        "import lime\n",
        "\n",
        "from yellowbrick.features import Rank2D\n",
        "from yellowbrick.classifier import ClassificationReport"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uBXWtXfl9cnC",
        "colab_type": "text"
      },
      "source": [
        "# Loading Data\n",
        "\n",
        "- Data can be in any of the popular formats - CSV, TXT, XLS/XLSX (Excel), sas7bdat (SAS), Stata, Rdata (R) etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j2EmRJu_9iGj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import CSV files\n",
        "Data= pd.read_csv(\"PATH_TO_FILE/example.csv\")\n",
        "# Import File from URL\n",
        "Data = pd.read_csv(\"URL_FOR_THE_FILE\")\n",
        "# Read Text File\n",
        "Data = pd.read_table(\"PATH_TO_FILE/example.txt\")\n",
        "Data = pd.read_csv(\"PATH_TO_FILE/example.txt\", sep =\"\\t\")\n",
        "# Read Excel File\n",
        "Data = pd.read_excel(\"PATH_TO_FILE(or)URL_FOR_THE_FILE/example.xls\",sheetname=\"Name\")\n",
        "#  Read SAS File\n",
        "Data = pd.read_sas('example.sas7bdat')\n",
        "# Read Stata File\n",
        "Data = pd.read_stata('example.dta')\n",
        "# Read R Data File\n",
        "result = pyreadr.read_r('C:/Users/sampledata.RData')\n",
        "print(result.keys()) # let's check what objects we got\n",
        "Data = result[\"df1\"] # extract the pandas data frame for object df1\n",
        "# Read SQL Table from Sqlite3 with .db exension\n",
        "conn = sqlite3.connect('C:/Users/Deepanshu/Downloads/flight.db')\n",
        "query = \"SELECT * FROM flight\"\n",
        "Data = pd.read_sql(query, con=conn)\n",
        "# Read Data from SPSS File\n",
        "Data, meta = pyreadstat.read_sav(\"file.sav\", apply_value_formats=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JaQNapATD7zf",
        "colab_type": "text"
      },
      "source": [
        "Modules to be used based on size of the data\n",
        "\n",
        "- Pandas - small DataSets upto 1 GB\n",
        "- Dask - Medium DataSets upto XX GB\n",
        "- Vaex - Large DataSets upto TB's"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LJZIIqrAqgu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Example\n",
        "\n",
        "data = pd.read_csv(\"https://raw.githubusercontent.com/Mineria/Titanic/master/csv/train.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GkhchE9AFGow",
        "colab_type": "text"
      },
      "source": [
        "# Preprocessing\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4vH-vLuYFsKT",
        "colab_type": "text"
      },
      "source": [
        "Basic preprocessing Steps:\n",
        "\n",
        "- Classifying the dependent and Independent Variables\n",
        "- Dealing with Missing Data\n",
        "- Dealing with Categorical Data\n",
        "- Splitting the Dataset into Training and Testing sets\n",
        "- Scaling the features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jIdtAipxFK3A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Example Preprocessing\n",
        "\n",
        "# Drop Ticket & Cabin \n",
        "data = data.drop(['Ticket', 'Cabin'], axis=1)\n",
        "\n",
        "# Get the title from name\n",
        "data['Title'] = data.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
        "data['Title'] = data['Title'].replace(['Lady', 'Countess','Capt', 'Col',\\\n",
        " \t'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
        "data['Title'] = data['Title'].replace('Mlle', 'Miss')\n",
        "data['Title'] = data['Title'].replace('Ms', 'Miss')\n",
        "data['Title'] = data['Title'].replace('Mme', 'Mrs')\n",
        "\n",
        "title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5} \n",
        "data['Title'] = data['Title'].map(title_mapping)\n",
        "data = data.drop(['Name', 'PassengerId'], axis=1)\n",
        "\n",
        "#Change Sex to Numeric\n",
        "data['Sex'] = data['Sex'].map( {'female': 1, 'male': 0} ).astype(int)\n",
        "\n",
        "#Add Family Size \n",
        "data['FamilySize'] = data['SibSp'] + data['Parch'] + 1\n",
        "data['IsAlone'] = 0\n",
        "data.loc[data['FamilySize'] == 1, 'IsAlone'] = 1\n",
        "data = data.drop(['Parch', 'SibSp', 'FamilySize'], axis=1)\n",
        "\n",
        "#Imputing Missing Value \n",
        "data['Age'].fillna(data['Age'].dropna().median(), inplace=True)\n",
        "data['Embarked'].fillna(data['Embarked'].dropna().mode()[0], inplace=True)\n",
        "\n",
        "# Categorizing Numerical Value \n",
        "data['FareBand'] = pd.qcut(data['Fare'], 4).astype(str)\n",
        "data['AgeBand'] = pd.qcut(data['Age'], 4).astype(str)\n",
        "data = data.drop(['Fare', 'Age'], axis=1)\n",
        "\n",
        "# Converting Embark to Number\n",
        "data['Embarked'] = data['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\n",
        "\n",
        "# \n",
        "data['FareBand'] = data['FareBand'].map( {'(-0.001, 7.91]': 0, '(31.0, 512.329]': 3, '(7.91, 14.454]': 1, '(14.454, 31.0]':2 } ).astype(int)\n",
        "data['AgeBand'] = data['AgeBand'].map( {'(0.419, 22.0]': 0, '(35.0, 80.0]': 3, '(22.0, 28.0]': 1, '(28.0, 35.0]':2 } ).astype(int)\n",
        "\n",
        "# Change in the cateogry Type & Data Columns to make it dummy\n",
        "df = data.drop(['Survived'], axis=1)\n",
        "df2 = df\n",
        "for col in df.columns:\n",
        "    df2[col] = df[col].astype('category')\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZV0TOuGH3SR",
        "colab_type": "text"
      },
      "source": [
        "# Model Selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kcpJubMHH8Hu",
        "colab_type": "text"
      },
      "source": [
        "## Simple Block to experiment all available Algorithm without setting any parameter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wgyT34aITxV",
        "colab_type": "text"
      },
      "source": [
        "#### Baseline Model Selection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCHRfkexH6Sk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Target = ['Survived']\n",
        "data1_x_bin = pd.get_dummies(df2)\n",
        "\n",
        "# X = data1_x_bin\n",
        "# y = Target\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)\n",
        "\n",
        "MLA = [\n",
        "    #Ensemble Methods\n",
        "    ensemble.AdaBoostClassifier(),\n",
        "    ensemble.BaggingClassifier(),\n",
        "    ensemble.ExtraTreesClassifier(),\n",
        "    ensemble.GradientBoostingClassifier(),\n",
        "    ensemble.RandomForestClassifier(),\n",
        "\n",
        "    #Gaussian Processes\n",
        "    gaussian_process.GaussianProcessClassifier(),\n",
        "    \n",
        "    #GLM\n",
        "    linear_model.LogisticRegressionCV(),\n",
        "    linear_model.PassiveAggressiveClassifier(),\n",
        "    linear_model.RidgeClassifierCV(),\n",
        "    linear_model.SGDClassifier(),\n",
        "    linear_model.Perceptron(),\n",
        "    \n",
        "    #Navies Bayes\n",
        "    naive_bayes.BernoulliNB(),\n",
        "    naive_bayes.GaussianNB(),\n",
        "    \n",
        "    #Nearest Neighbor\n",
        "    neighbors.KNeighborsClassifier(),\n",
        "    \n",
        "    #SVM\n",
        "    svm.SVC(probability=True),\n",
        "    svm.NuSVC(probability=True),\n",
        "    svm.LinearSVC(),\n",
        "    \n",
        "    #Trees    \n",
        "    tree.DecisionTreeClassifier(),\n",
        "    tree.ExtraTreeClassifier(),\n",
        "    \n",
        "    #Discriminant Analysis\n",
        "    discriminant_analysis.LinearDiscriminantAnalysis(),\n",
        "    discriminant_analysis.QuadraticDiscriminantAnalysis(),\n",
        "\n",
        "    \n",
        "    #xgboost: http://xgboost.readthedocs.io/en/latest/model.html\n",
        "    XGBClassifier()    \n",
        "    ]\n",
        "\n",
        "#split dataset in cross-validation with this splitter class: http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.ShuffleSplit.html#sklearn.model_selection.ShuffleSplit\n",
        "#note: this is an alternative to train_test_split\n",
        "cv_split = model_selection.ShuffleSplit(n_splits = 10, test_size = .3, train_size = .7, random_state = 0 ) # run model 10x with 60/30 split intentionally leaving out 10%\n",
        "\n",
        "#create table to compare MLA metrics\n",
        "MLA_columns = ['MLA Name', 'MLA Parameters','MLA Train Accuracy Mean', 'MLA Test Accuracy Mean', 'MLA Test Accuracy 3*STD' ,'MLA Time']\n",
        "MLA_compare = pd.DataFrame(columns = MLA_columns)\n",
        "\n",
        "#create table to compare MLA predictions\n",
        "MLA_predict = data[Target]  # Y \n",
        "\n",
        "#index through MLA and save performance to table\n",
        "row_index = 0\n",
        "Feature_Importance = {}\n",
        "\n",
        "for alg in MLA:\n",
        "\n",
        "    #set name and parameters\n",
        "    MLA_name = alg.__class__.__name__\n",
        "    MLA_compare.loc[row_index, 'MLA Name'] = MLA_name\n",
        "    MLA_compare.loc[row_index, 'MLA Parameters'] = str(alg.get_params())\n",
        "    \n",
        "    \n",
        "    #score model with cross validation: http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html#sklearn.model_selection.cross_validate\n",
        "    cv_results = model_selection.cross_validate(alg, data1_x_bin, data[Target], cv  = cv_split,return_train_score=True,scoring='f1')\n",
        "\n",
        "    MLA_compare.loc[row_index, 'MLA Time'] = cv_results['fit_time'].mean()\n",
        "    MLA_compare.loc[row_index, 'MLA Train Accuracy Mean'] = cv_results['train_score'].mean()\n",
        "    MLA_compare.loc[row_index, 'MLA Test Accuracy Mean'] = cv_results['test_score'].mean()   \n",
        "    #if this is a non-bias random sample, then +/-3 standard deviations (std) from the mean, should statistically capture 99.7% of the subsets\n",
        "    MLA_compare.loc[row_index, 'MLA Test Accuracy 3*STD'] = cv_results['test_score'].std()*3   #let's know the worst that can happen!\n",
        "    \n",
        "\n",
        "    #save MLA predictions - see section 6 for usage\n",
        "    alg.fit(data1_x_bin, data[Target])\n",
        "\n",
        "    try:\n",
        "      Feature_Importance[MLA_name] = alg.feature_importances_\n",
        "    except AttributeError:\n",
        "      pass\n",
        "      \n",
        "    MLA_predict[MLA_name] = alg.predict(data1_x_bin)\n",
        "    \n",
        "    row_index+=1\n",
        "\n",
        "    \n",
        "#print and sort table: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.sort_values.html\n",
        "MLA_compare.sort_values(by = ['MLA Test Accuracy Mean'], ascending = False, inplace = True)\n",
        "MLA_compare\n",
        "MLA_compare['Difference'] = (MLA_compare['MLA Test Accuracy Mean']-MLA_compare['MLA Train Accuracy Mean'])*100\n",
        "MLA_compare\n",
        "\n",
        "#MLA_predict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8da7MLv7Is_g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# sns.lineplot(x=\"MLA Train Accuracy Mean\", y=\"MLA Test Accuracy Mean\", hue=\"MLA Name\", data=MLA_compare)\n",
        "from matplotlib import pyplot as plt\n",
        "plt.figure(figsize=(18,8))\n",
        "cmap = sns.cubehelix_palette(dark=.1, light=0.8, as_cmap=True)\n",
        "# cmap = sns.palplot(sns.hls_palette(8, l=.3, s=.8))\n",
        "sns.scatterplot(x=\"MLA Train Accuracy Mean\", y=\"MLA Name\", data=MLA_compare,hue=\"MLA Time\",palette=cmap ,sizes=(20, 200))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pf5fkt7EIySW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# sns.lineplot(x=\"MLA Train Accuracy Mean\", y=\"MLA Test Accuracy Mean\", hue=\"MLA Name\", data=MLA_compare)\n",
        "from matplotlib import pyplot as plt\n",
        "plt.figure(figsize=(18,8))\n",
        "cmap = sns.cubehelix_palette(dark=.1, light=0.8, as_cmap=True)\n",
        "# cmap = sns.palplot(sns.hls_palette(8, l=.3, s=.8))\n",
        "sns.scatterplot(x=\"MLA Test Accuracy Mean\", y=\"MLA Name\", data=MLA_compare,hue=\"MLA Time\",palette=cmap ,sizes=(20, 200))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FTM-ttEkI3YO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# sns.lineplot(x=\"MLA Train Accuracy Mean\", y=\"MLA Test Accuracy Mean\", hue=\"MLA Name\", data=MLA_compare)\n",
        "from matplotlib import pyplot as plt\n",
        "plt.figure(figsize=(18,8))\n",
        "cmap = sns.cubehelix_palette(dark=.1, light=0.8, as_cmap=True)\n",
        "# cmap = sns.palplot(sns.hls_palette(8, l=.3, s=.8))\n",
        "sns.scatterplot(x=\"Difference\", y=\"MLA Name\", data=MLA_compare,hue=\"MLA Time\",palette=cmap ,sizes=(20, 200))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KCSTjvkOJO4H",
        "colab_type": "text"
      },
      "source": [
        "From the above results Decide the base models to tune it furthur"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WG2_G2OmJfOm",
        "colab_type": "text"
      },
      "source": [
        "#### Feature Selection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ai2azrsCJKze",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get Importance Feature \n",
        "\n",
        "feature_names = data1_x_bin.columns\n",
        "feat_imp_df = pd.DataFrame.from_dict(Feature_Importance)\n",
        "feat_imp_df.index = feature_names\n",
        "feat_imp_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vHxla9sJuIz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "mms = MinMaxScaler()\n",
        "\n",
        "scaled_fi = pd.DataFrame(data=mms.fit_transform(feat_imp_df),\n",
        "                         columns=feat_imp_df.columns,\n",
        "                         index=feat_imp_df.index)\n",
        "\n",
        "scaled_fi['Overall'] = scaled_fi.sum(axis=1)\n",
        "print(scaled_fi.head())\n",
        "ordered_ranking = scaled_fi.sort_values('Overall', ascending=False)\n",
        "fig, ax = plt.subplots(figsize=(10,7), dpi=80)\n",
        "sns.barplot(data=ordered_ranking, y=ordered_ranking.index, x='Overall', palette='magma')\n",
        "ax.spines['right'].set_visible(False)\n",
        "ax.spines['top'].set_visible(False)\n",
        "ax.spines['bottom'].set_visible(False)\n",
        "ax.xaxis.set_visible(False)\n",
        "ax.grid(False)\n",
        "ax.set_title('Feature Importances for all Models');"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNvQR_5OJ43B",
        "colab_type": "text"
      },
      "source": [
        "Decide the number of fetures you want to take in your model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7bA3t5xPJ2Td",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Re-Building the model with only top 10 Features \n",
        "\n",
        "scaled_sorted = scaled_fi.sort_values(by = ['Overall'], ascending = False)\n",
        "scaled_sorted[:5].index\n",
        "important_col = list(scaled_sorted[:10].index)\n",
        "Target = ['Survived']\n",
        "data1_x_bin = pd.get_dummies(df2)\n",
        "data1_x_bin = data1_x_bin[important_col]\n",
        "\n",
        "# X = data1_x_bin\n",
        "# y = Target\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)\n",
        "\n",
        "MLA = [\n",
        "    #Ensemble Methods\n",
        "    ensemble.AdaBoostClassifier(),\n",
        "    ensemble.BaggingClassifier(),\n",
        "    ensemble.ExtraTreesClassifier(),\n",
        "    ensemble.GradientBoostingClassifier(),\n",
        "    ensemble.RandomForestClassifier(),\n",
        "\n",
        "    #Gaussian Processes\n",
        "    gaussian_process.GaussianProcessClassifier(),\n",
        "    \n",
        "    #GLM\n",
        "    linear_model.LogisticRegressionCV(),\n",
        "    linear_model.PassiveAggressiveClassifier(),\n",
        "    linear_model.RidgeClassifierCV(),\n",
        "    linear_model.SGDClassifier(),\n",
        "    linear_model.Perceptron(),\n",
        "    \n",
        "    #Navies Bayes\n",
        "    naive_bayes.BernoulliNB(),\n",
        "    naive_bayes.GaussianNB(),\n",
        "    \n",
        "    #Nearest Neighbor\n",
        "    neighbors.KNeighborsClassifier(),\n",
        "    \n",
        "    #SVM\n",
        "    svm.SVC(probability=True),\n",
        "    svm.NuSVC(probability=True),\n",
        "    svm.LinearSVC(),\n",
        "    \n",
        "    #Trees    \n",
        "    tree.DecisionTreeClassifier(),\n",
        "    tree.ExtraTreeClassifier(),\n",
        "    \n",
        "    #Discriminant Analysis\n",
        "    discriminant_analysis.LinearDiscriminantAnalysis(),\n",
        "    discriminant_analysis.QuadraticDiscriminantAnalysis(),\n",
        "\n",
        "    \n",
        "    #xgboost: http://xgboost.readthedocs.io/en/latest/model.html\n",
        "    XGBClassifier()    \n",
        "    ]\n",
        "\n",
        "#split dataset in cross-validation with this splitter class: http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.ShuffleSplit.html#sklearn.model_selection.ShuffleSplit\n",
        "#note: this is an alternative to train_test_split\n",
        "cv_split = model_selection.ShuffleSplit(n_splits = 10, test_size = .3, train_size = .7, random_state = 0 ) # run model 10x with 60/30 split intentionally leaving out 10%\n",
        "\n",
        "#create table to compare MLA metrics\n",
        "MLA_columns = ['MLA Name', 'MLA Parameters','MLA Train Accuracy Mean', 'MLA Test Accuracy Mean', 'MLA Test Accuracy 3*STD' ,'MLA Time']\n",
        "MLA_compare = pd.DataFrame(columns = MLA_columns)\n",
        "\n",
        "#create table to compare MLA predictions\n",
        "MLA_predict = data[Target]\n",
        "\n",
        "#index through MLA and save performance to table\n",
        "row_index = 0\n",
        "Feature_Importance = {}\n",
        "\n",
        "for alg in MLA:\n",
        "\n",
        "    #set name and parameters\n",
        "    MLA_name = alg.__class__.__name__\n",
        "    MLA_compare.loc[row_index, 'MLA Name'] = MLA_name\n",
        "    MLA_compare.loc[row_index, 'MLA Parameters'] = str(alg.get_params())\n",
        "    \n",
        "    \n",
        "    #score model with cross validation: http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html#sklearn.model_selection.cross_validate\n",
        "    cv_results = model_selection.cross_validate(alg, data1_x_bin, data[Target], cv  = cv_split,return_train_score=True,scoring='f1')\n",
        "\n",
        "    MLA_compare.loc[row_index, 'MLA Time'] = cv_results['fit_time'].mean()\n",
        "    MLA_compare.loc[row_index, 'MLA Train Accuracy Mean'] = cv_results['train_score'].mean()\n",
        "    MLA_compare.loc[row_index, 'MLA Test Accuracy Mean'] = cv_results['test_score'].mean()   \n",
        "    #if this is a non-bias random sample, then +/-3 standard deviations (std) from the mean, should statistically capture 99.7% of the subsets\n",
        "    MLA_compare.loc[row_index, 'MLA Test Accuracy 3*STD'] = cv_results['test_score'].std()*3   #let's know the worst that can happen!\n",
        "    \n",
        "\n",
        "    #save MLA predictions - see section 6 for usage\n",
        "    alg.fit(data1_x_bin, data[Target])\n",
        "\n",
        "    try:\n",
        "      Feature_Importance[MLA_name] = alg.feature_importances_\n",
        "    except AttributeError:\n",
        "      pass\n",
        "      \n",
        "    MLA_predict[MLA_name] = alg.predict(data1_x_bin)\n",
        "    \n",
        "    row_index+=1\n",
        "\n",
        "    \n",
        "#print and sort table: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.sort_values.html\n",
        "MLA_compare.sort_values(by = ['MLA Test Accuracy Mean'], ascending = False, inplace = True)\n",
        "MLA_compare\n",
        "MLA_compare['Difference'] = (MLA_compare['MLA Test Accuracy Mean']-MLA_compare['MLA Train Accuracy Mean'])*100\n",
        "MLA_compare"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejXjYwFBKFmT",
        "colab_type": "text"
      },
      "source": [
        "From the results again decide the models for furthur tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d68WpFoyKNTC",
        "colab_type": "text"
      },
      "source": [
        "## Grid Search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvcgvttMKMNJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Helper Class for Initilizing GridSearch\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "class EstimatorSelectionHelper:\n",
        "\n",
        "    def __init__(self, models, params):\n",
        "        if not set(models.keys()).issubset(set(params.keys())):\n",
        "            missing_params = list(set(models.keys()) - set(params.keys()))\n",
        "            raise ValueError(\"Some estimators are missing parameters: %s\" % missing_params)\n",
        "        self.models = models\n",
        "        self.params = params\n",
        "        self.keys = models.keys()\n",
        "        self.grid_searches = {}\n",
        "        self.best_params = {}\n",
        "        self.feature_importance = {}\n",
        "        self.FeatureImportanceAlgo = ['DecisionTreeClassifier','RandomForestClassifier','ExtraTreesClassifier','GradientBoostingClassifier']\n",
        "\n",
        "    def fit(self, X, y, cv=3, n_jobs=3, verbose=1, scoring=None, refit=True):\n",
        "        for key in self.keys:\n",
        "            print(\"Running GridSearchCV for %s.\" % key)\n",
        "            model = self.models[key]\n",
        "            params = self.params[key]\n",
        "            gs = GridSearchCV(model, params, cv=cv, n_jobs=n_jobs,\n",
        "                              verbose=verbose, scoring=scoring, refit=refit,\n",
        "                              return_train_score=True)\n",
        "            gs.fit(X,y)\n",
        "            self.grid_searches[key] = gs  \n",
        "            self.best_params[key]  = str(gs.best_params_)\n",
        "            if key in self.FeatureImportanceAlgo:\n",
        "              self.feature_importance[key]= gs.best_estimator_ .feature_importances_\n",
        "\n",
        "            # print (gs.best_params_.feature_importances_ )\n",
        "            # try:\n",
        "            #   print(gs.best_params_.feature_importances_ )\n",
        "            #   self.feature_importance[key]= gs.best_params_.feature_importances_ \n",
        "            # except AttributeError:\n",
        "            #   pass\n",
        "\n",
        "    def returnBestParamDF(self):\n",
        "      d = self.best_params\n",
        "      BestParamDF = pd.DataFrame.from_dict([d.keys(), d.values()]).T\n",
        "      return BestParamDF\n",
        "\n",
        "    # def Feature_Importance(self):\n",
        "    #   for each\n",
        "\n",
        "    # def returnFeatureImportance(self):\n",
        "\n",
        "\n",
        "    def score_summary(self, sort_by='mean_score'):\n",
        "        def row(key, scores, params):\n",
        "            d = {\n",
        "                 'estimator': key,\n",
        "                 'min_score': min(scores),\n",
        "                 'max_score': max(scores),\n",
        "                 'mean_score': np.mean(scores),\n",
        "                 'std_score': np.std(scores),\n",
        "            }\n",
        "            return pd.Series({**params,**d})\n",
        "\n",
        "        rows = []\n",
        "        for k in self.grid_searches:\n",
        "            print(k)\n",
        "            params = self.grid_searches[k].cv_results_['params']\n",
        "            scores = []\n",
        "            for i in range(self.grid_searches[k].cv):\n",
        "                key = \"split{}_test_score\".format(i)\n",
        "                r = self.grid_searches[k].cv_results_[key]        \n",
        "                scores.append(r.reshape(len(params),1))\n",
        "\n",
        "            all_scores = np.hstack(scores)\n",
        "            for p, s in zip(params,all_scores):\n",
        "                rows.append((row(k, s, p)))\n",
        "\n",
        "        df = pd.concat(rows, axis=1).T.sort_values([sort_by], ascending=False)\n",
        "\n",
        "        columns = ['estimator', 'min_score', 'mean_score', 'max_score', 'std_score']\n",
        "        columns = columns + [c for c in df.columns if c not in columns]\n",
        "\n",
        "        return df[columns]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-hpWB-GKYZm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "models1 = {\n",
        "    \n",
        "    'LogisticRegression':LogisticRegression(),\n",
        "    'DecisionTreeClassifier': DecisionTreeClassifier(),\n",
        "    'RandomForestClassifier': RandomForestClassifier(),\n",
        "    'KNNClassifier': KNeighborsClassifier(),\n",
        "    'SVC': SVC(),\n",
        "    'ExtraTreesClassifier': ExtraTreesClassifier(),\n",
        "    'AdaBoostClassifier': AdaBoostClassifier(),\n",
        "    'GradientBoostingClassifier': GradientBoostingClassifier()\n",
        "    \n",
        "}\n",
        "\n",
        "params1 = {\n",
        "    'LogisticRegression': { \"C\":np.logspace(-3,3,7),\n",
        "                           \"penalty\":[\"l1\",\"l2\"]\n",
        "                           },\n",
        "    'DecisionTreeClassifier': {'criterion' : ['gini', 'entropy'],\n",
        "                               'splitter' : ['random', 'best'],\n",
        "                               'max_depth':[2,5,10], \n",
        "                               'min_samples_leaf':[2,5,10]\n",
        "                               },\n",
        "    'RandomForestClassifier': { 'n_estimators': [16, 32] \n",
        "                               },\n",
        "    'ExtraTreesClassifier': { 'n_estimators': [16, 32] \n",
        "                             },\n",
        "    'KNNClassifier':{ 'n_neighbors': [5,10,15,20],\n",
        "                     'algorithm' : ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
        "                     },\n",
        "    'AdaBoostClassifier':  { 'n_estimators': [16, 32] \n",
        "                            },\n",
        "    'GradientBoostingClassifier': { 'n_estimators': [16, 32],\n",
        "                                   'learning_rate': [0.8, 1.0]\n",
        "                                   },\n",
        "    'SVC': [\n",
        "            {'kernel': ['linear'],\n",
        "             'C': [1, 10]\n",
        "             },\n",
        "            {'kernel': ['rbf'], \n",
        "             'C': [1, 10],\n",
        "             'gamma': [0.001, 0.0001]\n",
        "             },\n",
        "            ]\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3srrPNVjKp9g",
        "colab_type": "text"
      },
      "source": [
        "- Add as many parameters required for tuning thats upto You"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LmDrbB-gMk02",
        "colab_type": "text"
      },
      "source": [
        "#### Model Selection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhct9agVKhgU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "helper1 = EstimatorSelectionHelper(models1, params1)\n",
        "helper1.fit(data1_x_bin, data[Target], scoring='f1', n_jobs=-1)\n",
        "\n",
        "# To run with important column\n",
        "# ImpCol = ['','']\n",
        "# helper1.fit(data1_x_bin[ImpCol], data[Target], scoring='f1', n_jobs=-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3PL70nWBMX7U",
        "colab_type": "text"
      },
      "source": [
        "#### Feature Selection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQhfT3acKpWw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "feature_names = data1_x_bin.columns\n",
        "feat_imp_df = pd.DataFrame.from_dict(helper1.feature_importance)\n",
        "feat_imp_df.index = feature_names\n",
        "feat_imp_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9wXvXOHKoUV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "mms = MinMaxScaler()\n",
        "\n",
        "scaled_fi = pd.DataFrame(data=mms.fit_transform(feat_imp_df),\n",
        "                         columns=feat_imp_df.columns,\n",
        "                         index=feat_imp_df.index)\n",
        "\n",
        "scaled_fi['Overall'] = scaled_fi.sum(axis=1)\n",
        "print(scaled_fi.head())\n",
        "ordered_ranking = scaled_fi.sort_values('Overall', ascending=False)\n",
        "fig, ax = plt.subplots(figsize=(10,7), dpi=80)\n",
        "sns.barplot(data=ordered_ranking, y=ordered_ranking.index, x='Overall', palette='magma')\n",
        "ax.spines['right'].set_visible(False)\n",
        "ax.spines['top'].set_visible(False)\n",
        "ax.spines['bottom'].set_visible(False)\n",
        "ax.xaxis.set_visible(False)\n",
        "ax.grid(False)\n",
        "ax.set_title('Feature Importances for all Models');"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltwgwTSXLzRy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Evalution Metrics for all Algorithms\n",
        "helper1.score_summary(sort_by='max_score')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-t_zV4mL4N0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Getting the Best Parameter\n",
        "helper1.returnBestParamDF()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y2YihFhzUpOy",
        "colab_type": "text"
      },
      "source": [
        "# Ensemble Learning\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PWPQhZAWUk7e",
        "colab_type": "text"
      },
      "source": [
        "Ensembles combine predictions from different models to generate a final prediction, and the more models we include the better it performs.\n",
        "\n",
        "![](https://www.dataquest.io/wp-content/uploads/2019/01/ensemble_network.png)\n",
        "\n",
        "[Source](http://flennerhag.com/2017-04-18-introduction-to-ensembles/)\n",
        "\n",
        "Some of the Ensemble Learning Techniques are\n",
        "\n",
        "- Basic Ensemble Techniques\n",
        "--  Max Voting\n",
        "--  Averaging\n",
        "--  Weighted Average\n",
        "- Advanced Ensemble Techniques\n",
        "--  Stacking\n",
        "--  Blending\n",
        "--  Bagging\n",
        "--  Boosting\n",
        "- Algorithms based on Bagging and Boosting\n",
        "--  Bagging meta-estimator\n",
        "--  Random Forest\n",
        "--  AdaBoost\n",
        "--  GBM\n",
        "--  XGB\n",
        "--  Light GBM\n",
        "--  CatBoost\n",
        "\n",
        "\n",
        "[Source](https://www.analyticsvidhya.com/blog/2018/06/comprehensive-guide-for-ensemble-models/)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o4xsAE4nYeGK",
        "colab_type": "text"
      },
      "source": [
        "## Max Voting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uefjGwwZUj3Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vote_est = [\n",
        "    #Ensemble Methods: http://scikit-learn.org/stable/modules/ensemble.html\n",
        "    \n",
        "    ('rfc', ensemble.RandomForestClassifier()),\n",
        "    \n",
        "    #Nearest Neighbor: http://scikit-learn.org/stable/modules/neighbors.html\n",
        "    ('knn', neighbors.KNeighborsClassifier()),\n",
        "    \n",
        "    #xgboost: http://xgboost.readthedocs.io/en/latest/model.html\n",
        "   ('xgb', XGBClassifier()),\n",
        "   ('lgbm',LGBMClassifier())\n",
        "\n",
        "]\n",
        "\n",
        "seed = 123\n",
        "skf = model_selection.ShuffleSplit(n_splits = 10, test_size = .3, train_size = .6, random_state = seed )\n",
        "#Hard Vote or majority rules\n",
        "vote_hard = ensemble.VotingClassifier(estimators = vote_est , voting = 'hard')\n",
        "vote_hard_cv = model_selection.cross_validate(vote_hard, data1_x_bin, data[Target], cv  = skf,scoring='f1')\n",
        "vote_hard.fit(data1_x_bin, data[Target])\n",
        "#print(\"Hard Voting Training w/bin score mean: {:.2f}\". format(vote_hard_cv['train_score'].mean()*100)) \n",
        "print(\"Hard Voting Test w/bin score mean: {:.2f}\". format(vote_hard_cv['test_score'].mean()*100))\n",
        "print(\"Hard Voting Test w/bin score 3*std: +/- {:.2f}\". format(vote_hard_cv['test_score'].std()*100*3))\n",
        "print('-'*10)\n",
        "\n",
        "\n",
        "#Soft Vote or weighted probabilities\n",
        "vote_soft = ensemble.VotingClassifier(estimators = vote_est , voting = 'soft')\n",
        "vote_soft_cv = model_selection.cross_validate(vote_soft, data1_x_bin, data[Target], cv  = skf,scoring='f1')\n",
        "vote_soft.fit(data1_x_bin, data[Target])\n",
        "\n",
        "#print(\"Soft Voting Training w/bin score mean: {:.2f}\". format(vote_soft_cv['train_score'].mean()*100)) \n",
        "print(\"Soft Voting Test w/bin score mean: {:.2f}\". format(vote_soft_cv['test_score'].mean()*100))\n",
        "print(\"Soft Voting Test w/bin score 3*std: +/- {:.2f}\". format(vote_soft_cv['test_score'].std()*100*3))\n",
        "print('-'*10)z"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTTTqyX3Y1lD",
        "colab_type": "text"
      },
      "source": [
        "## Stacking"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "apYtuS36ZMkp",
        "colab_type": "text"
      },
      "source": [
        "#### ML Extend"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "baI52PxaY4wD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from mlxtend.classifier import StackingClassifier\n",
        "lgbm_cl = LGBMClassifier(random_state=seed)\n",
        "rf_cl = RandomForestClassifier(10, random_state=seed)\n",
        "gdb_cl = GradientBoostingClassifier(random_state=seed)\n",
        "logreg = LogisticRegression()\n",
        "sclf = StackingClassifier(classifiers=[lgbm_cl, rf_cl,gdb_cl],\n",
        "                          meta_classifier=logreg)\n",
        "\n",
        "\n",
        "scores = model_selection.cross_val_score(sclf, data1_x_bin, data[Target], \n",
        "                                              cv=3, scoring='f1')\n",
        "print(\"Accuracy: %0.2f (+/- %0.2f)\" \n",
        "      % (scores.mean(), scores.std()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j39AvbbgZXIU",
        "colab_type": "text"
      },
      "source": [
        "#### VecStack"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MbPWsm4RZZKf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#1st level model\n",
        "X_train, X_test, y_train, y_test = train_test_split(data1_x_bin, data[Target], test_size=0.2)\n",
        "\n",
        "models = [lgbm_cl,rf_cl,gdb_cl]\n",
        "S_train, S_test = stacking(models, X_train, y_train, X_test, \n",
        "    regression = False, metric = metrics.f1_score, n_folds = 4 , \n",
        "    shuffle = True, random_state = 0, verbose = 2)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCX6ydiYZmih",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#2nd level model\n",
        "# Initialize 2nd level model\n",
        "model = XGBClassifier(random_state=0, n_jobs=-1, learning_rate=0.1, \n",
        "                      n_estimators=100, max_depth=3)\n",
        "    \n",
        "# Fit 2nd level model\n",
        "model = model.fit(S_train, y_train)\n",
        "\n",
        "# Predict\n",
        "y_pred = model.predict(S_test)\n",
        "\n",
        "# Final prediction score\n",
        "print('Final prediction score: [%.8f]' % metrics.f1_score(y_test, y_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AANXmTa5Zw7X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#New Experiment \n",
        "\n",
        "#Level 1\n",
        "X_train, X_test, y_train, y_test = train_test_split(data1_x_bin, data[Target], test_size=0.2)\n",
        "\n",
        "models = [\n",
        "    ExtraTreesClassifier(random_state=0, n_jobs=-1, \n",
        "                         n_estimators=100, max_depth=3),\n",
        "        \n",
        "    RandomForestClassifier(random_state=0, n_jobs=-1, \n",
        "                           n_estimators=100, max_depth=3),\n",
        "        \n",
        "    XGBClassifier(random_state=0, n_jobs=-1, learning_rate=0.1, \n",
        "                  n_estimators=100, max_depth=3)\n",
        "]\n",
        "\n",
        "S_train, S_test = stacking(models,                     # list of models\n",
        "                           X_train, y_train, X_test,   # data\n",
        "                           regression=False,           # classification task (if you need \n",
        "                                                       #     regression - set to True)\n",
        "                           mode='oof_pred_bag',        # mode: oof for train set, predict test \n",
        "                                                       #     set in each fold and vote\n",
        "                           needs_proba=False,          # predict class labels (if you need \n",
        "                                                       #     probabilities - set to True) \n",
        "                           save_dir=None,              # do not save result and log (to save \n",
        "                                                       #     in current dir - set to '.')\n",
        "                           metric=metrics.f1_score,      # metric: callable\n",
        "                           n_folds=4,                  # number of folds\n",
        "                           stratified=True,            # stratified split for folds\n",
        "                           shuffle=True,               # shuffle the data\n",
        "                           random_state=0,             # ensure reproducibility\n",
        "                           verbose=2)      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xI6p34f2Z1X4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#2nd level model\n",
        "# Initialize 2nd level model\n",
        "# model = XGBClassifier(random_state=0, n_jobs=-1, learning_rate=0.1, \n",
        "#                       n_estimators=100, max_depth=3)\n",
        "    \n",
        "model = LogisticRegression()\n",
        "# model = KNeighborsClassifier(n_neighbors=5)\n",
        "# Fit 2nd level model\n",
        "model = model.fit(S_train, y_train)\n",
        "\n",
        "# Predict\n",
        "y_pred = model.predict(S_test)\n",
        "\n",
        "# Final prediction score\n",
        "print('Final prediction score: [%.8f]' % metrics.f1_score(y_test, y_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-2L6tt-Z7cp",
        "colab_type": "text"
      },
      "source": [
        "# Automated Machine Learning (AutoML)\n",
        "\n",
        "- Automated machine learning is the process of automating end-to-end the process of applying machine learning to real-world problems."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_DvLcqPcTFt",
        "colab_type": "text"
      },
      "source": [
        "## TPot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5yJ5qwrZ_9s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#100 pipelines\n",
        "#5 generations\n",
        "# Create a tpot object with a few parameters\n",
        "tpot = TPOTClassifier(generations=50,scoring ='f1', \n",
        "                    max_time_mins = 120, \n",
        "                    n_jobs = -1,\n",
        "                    verbosity = 2,\n",
        "                    cv = 3)\n",
        "\n",
        "# Convert to numpy arrays\n",
        "training_features = np.array(X_train)\n",
        "\n",
        "\n",
        "# Sklearn wants the labels as one-dimensional vectors\n",
        "training_targets = np.array(y_train).reshape((-1,))\n",
        "\n",
        "# Fit the tpot model on the training data\n",
        "tpot.fit(training_features, training_targets)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRntd3bWcd6H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Show the final model\n",
        "print(tpot.fitted_pipeline_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwfsIMVFcmPL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Evaluate the final model\n",
        "print(tpot.score(X_test, y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jCueiB1pcniM",
        "colab_type": "text"
      },
      "source": [
        "## MLBox"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2WEA6yANeeOj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "paths = [\"train.csv\",\n",
        "         \"test.csv\"]\n",
        "target_name = \"Column_name_of_the_target_feaure\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZVMitJge3Yi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rd = Reader(sep = ',')\n",
        "df = rd.train_test_split(paths, target_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ArNVZEHBe9nF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dft = Drift_thresholder()\n",
        "df = dft.fit_transform(df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3rwvqEde9ON",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "opt = Optimiser(scoring = 'accuracy', n_folds = 3)\n",
        "opt.evaluate(None, df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vj_qKjXXfDEI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "space = {\n",
        "    \n",
        "        'est__strategy':{\"search\":\"choice\",\n",
        "                                  \"space\":[\"LightGBM\"]},    \n",
        "        'est__n_estimators':{\"search\":\"choice\",\n",
        "                                  \"space\":[150]},    \n",
        "        'est__colsample_bytree':{\"search\":\"uniform\",\n",
        "                                  \"space\":[0.8,0.95]},\n",
        "        'est__subsample':{\"search\":\"uniform\",\n",
        "                                  \"space\":[0.8,0.95]},\n",
        "        'est__max_depth':{\"search\":\"choice\",\n",
        "                                  \"space\":[5,6,7,8,9]},\n",
        "        'est__learning_rate':{\"search\":\"choice\",\n",
        "                                  \"space\":[0.07]} \n",
        "    \n",
        "        }\n",
        "\n",
        "best = opt.optimise(space, df,15)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iDxoZVyNfQez",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prd = Predictor()\n",
        "prd.fit_predict(best, df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7GOywNYscs3A",
        "colab_type": "text"
      },
      "source": [
        "## H20"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JbboA7oLcsGa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(h2o.__version__)\n",
        "\n",
        "\n",
        "h2o.init(max_mem_size='16G')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DAbTXfoighCS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "train = h2o.import_file(\"train.csv\")\n",
        "train = train[:250000,:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwqCRdxagg1O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = train.columns[:-1]\n",
        "y = 'Column_name_of_the_target_feaure'\n",
        "# For binary classification, response should be a factor\n",
        "train[y] = train[y].asfactor()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8uKfGlEQggmr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "aml = H2OAutoML(max_models=30, seed=45, max_runtime_secs=7200)\n",
        "aml.train(x=x, y=y, training_frame=train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzYvRLN0hE3i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# View the AutoML Leaderboard\n",
        "lb = aml.leaderboard\n",
        "lb.head(rows=lb.nrows)  # Print all rows instead of default (10 rows)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1w-JXvQIhEf9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The leader model is stored here\n",
        "aml.leader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s92UcS1dggUs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "h2o.remove(train)\n",
        "test = h2o.import_file(\"test.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZC5qrZPjiqtT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "h20_pred = aml.predict(test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPh6URyRaIk9",
        "colab_type": "text"
      },
      "source": [
        "# Creating API"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYTsr2c7aLVs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(data1_x_bin, data[Target], test_size=0.2)\n",
        "\n",
        "lr = LogisticRegression()\n",
        "lr.fit(X_train, y_train)\n",
        "\n",
        "joblib.dump(lr, 'model.pkl')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azA1nxw_aO1i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loading Model \n",
        "\n",
        "lr = joblib.load('model.pkl')\n",
        "print('Final prediction score: [%.8f]' % metrics.f1_score(y_test, lr.predict(X_test)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrM4ZcdmaXD_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data1_x_bin[:10].to_csv(\"testing_data.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KiDHdGdKaaOr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "list(data1_x_bin[:10].columns)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tv61aUL-ae_9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "str(lr.predict(data1_x_bin[:10]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JjOxgqyOb0AB",
        "colab_type": "text"
      },
      "source": [
        "# Model Interpretation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "diFLDZvJb3r5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dtree = DecisionTreeClassifier()\n",
        "dtree.fit(X_train, y_train)\n",
        "dtree.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ODaGgZ4UjYqD",
        "colab_type": "text"
      },
      "source": [
        "## Eli5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fVX5lkdb9Hu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "perm = PermutationImportance(dtree , random_state=101).fit(X_test, y_test)      # Evaluate the permutation importance \n",
        "eli5.show_weights(perm, feature_names = X_test.columns.values)    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kGgmFtMvjcfV",
        "colab_type": "text"
      },
      "source": [
        "## Shap"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTEI7-RscCKX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "row_to_show = 7                                                                # The row for which we want to check the SHAP explanations\n",
        "data_to_predict = X_test.iloc[row_to_show]\n",
        "\n",
        "data_to_preddict_array = data_to_predict.values.reshape(1,-1)\n",
        "\n",
        "dtree_pred = dtree.predict_proba(data_to_preddict_array)  \n",
        "\n",
        "dtree.predict(data_to_preddict_array)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tcTRkOzqcFXQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Object that can calculate Shap values\n",
        "explainer = shap.TreeExplainer(dtree)                                       # SHAP Tree Explainer\n",
        "\n",
        "# Calculate the shap values\n",
        "shap_values = explainer.shap_values(data_to_predict) \n",
        "shap.initjs()\n",
        "shap.force_plot(explainer.expected_value[1], shap_values[1], data_to_predict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YmrKAQfhkHHS",
        "colab_type": "text"
      },
      "source": [
        "## Lime"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rE35JVSkKNR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Create an Explainer inhertance of the data\n",
        "explainer = lime.lime_tabular.LimeTabularExplainer(X_train.values, feature_names=X_train.columns.tolist(), class_names=y_train.unique())\n",
        "\n",
        "# Create a lambda function to use model to predict the data\n",
        "predict_fn = lambda x: model.predict_proba(x).astype(float)\n",
        "\n",
        "#using Explainer to Explain the predictions\n",
        "exp = explainer.explain_instence(X_test.values[0], predict_fn, num_features=6)\n",
        "exp.show_in_notebook(show_all=False)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHGoM7A5kOTd",
        "colab_type": "text"
      },
      "source": [
        "## Yellowbrick"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MEyPVIsfkRip",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# HeatMap for Co-Relation\n",
        "\n",
        "visualizer = Rank2D(algorithm=\"pearson\", size=(1080, 720))\n",
        "visualizer.fit_transform(X_train)\n",
        "visualizer.poof()\n",
        "\n",
        "\n",
        "# Evaluation Metrics\n",
        "visualizer = ClassificationReport(model, size=(1080, 720))\n",
        "visualizer.fit(X_train, y_train)\n",
        "visualizer.score(X_train, y_train)\n",
        "visualizer.poff()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzJ8oVo6bKs_",
        "colab_type": "text"
      },
      "source": [
        "# Using API in WebApp (Flask)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dd2KahSybQ7U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%writefile server.py\n",
        "\n",
        "#!/usr/bin/env python\n",
        "# -*- coding: utf-8 -*-\n",
        "from __future__ import unicode_literals\n",
        "from flask import Flask, request, jsonify\n",
        "from sklearn.externals import joblib\n",
        "import traceback\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import socket\n",
        "print(socket.gethostbyname(socket.getfqdn(socket.gethostname())))\n",
        "\n",
        "\n",
        "from flask import Flask, jsonify\n",
        "app = Flask(__name__)\n",
        "@app.route('/predict', methods=['POST'])\n",
        "def predict():\n",
        "     json_ = request.get_json()\n",
        "     lr = joblib.load(\"model.pkl\")\n",
        "     Columns = ['Title_1',\n",
        " 'Sex_0',\n",
        " 'Sex_1',\n",
        " 'Pclass_3',\n",
        " 'Pclass_1',\n",
        " 'Title_2',\n",
        " 'Title_3',\n",
        " 'IsAlone_1',\n",
        " 'Title_5',\n",
        " 'FareBand_3']\n",
        "\n",
        "    #  query_df = pd.DataFrame(json_)\n",
        "     query_df = pd.read_csv(\"testing_data.csv\",index_col=None)\n",
        "     query_df = query_df[Columns]\n",
        "    #  query = pd.get_dummies(query_df)\n",
        "     print (query_df)\n",
        "     prediction = lr.predict(query_df)\n",
        "     return str(prediction)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    try:\n",
        "        port = int(sys.argv[1]) # This is for a command-line input\n",
        "    except:\n",
        "        port = 12345 # If you don't provide any port the port will be set to 12345\n",
        "    global lr\n",
        "    lr = joblib.load(\"model.pkl\") # Load \"model.pkl\"\n",
        "    print ('Model loaded')\n",
        "    # test_data = pd.read_csv(\"testing_data.csv\")\n",
        "    # return lr.predict(test_data)\n",
        "    app.run(threaded=True,debug=True,port=8888)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P02FB4txbYBA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import subprocess\n",
        "import sys\n",
        "import time\n",
        "import socket\n",
        "# Start a subprocess that runs the Flask server\n",
        "p = subprocess.Popen([sys.executable, \"-m\", \"flask\", \"run\"], env=dict(**os.environ, FLASK_APP=\"server.py\"), stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "\n",
        "# Start two subthreads that forward the output from the Flask server to the output of the Jupyter notebook\n",
        "def forward(i, o):\n",
        "    while p.poll() is None:\n",
        "        l = i.readline().decode('utf-8')\n",
        "        if l:\n",
        "            o.write(\"[SERVER] \" + l)\n",
        "\n",
        "import threading\n",
        "threading.Thread(target=forward, args=(p.stdout, sys.stdout)).start()\n",
        "threading.Thread(target=forward, args=(p.stderr, sys.stderr)).start()\n",
        "import socket\n",
        "print(socket.gethostbyname(socket.getfqdn(socket.gethostname())))\n",
        "# sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n",
        "# Let's give the server a bit of time to make sure it has started\n",
        "time.sleep(2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7nkymA3kbdmh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Requesting to predict\n",
        "\n",
        "import requests\n",
        "# r = requests.get(\"http://172.28.0.2/\")\n",
        "r = requests.post(\" http://127.0.0.1:5000/predict\",data=data1_x_bin[:1].to_json())\n",
        "print(r.status_code)\n",
        "print(r.encoding)\n",
        "print(r.apparent_encoding)\n",
        "print(r.text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nHVYzvLbmfp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ps -fA | grep python\n",
        "!sudo kill 2230"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cLw-qKgj0Wcu",
        "colab_type": "text"
      },
      "source": [
        "#Happy Learning"
      ]
    }
  ]
}